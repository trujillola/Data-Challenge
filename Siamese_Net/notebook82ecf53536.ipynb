{"cells":[{"cell_type":"markdown","metadata":{"id":"14aeb-3A9TYO"},"source":["# One-shot Siamese Neural Network\n","In this assignment we were tasked with creating a Convolutional Neural Networks (CNNs). \n","A step-by-step CNNs tutorial you can find [here (DeepLearning.ai)](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF).\n","\n","The assignment is to be carried out using Python V3.6 (or higher) and TensorFlow 2.0 (or higher).\n","\n","In this assignment, we were tasked with creating a One-shot Siamese Neural Network, using TensorFlow 2.0, based on the work presented by Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov.\n","As specified, we used the “Labeled Faces in the Wild” dataset with over 5,700 different people. Some people have a single image, while others have dozens. We used, as requested, the improved dataset where the faces were aligned automatically using specialized software.\n","\n","# Table of Contents\n","1. [Authors](#Authors)\n","2. [Purposes of The Assignment](#Purposes-of-The-Assignment)\n","3. [Instructions](#Instructions)\n","4. [Dataset Analysis](#Dataset-Analysis)\n","5. [Code Design](#Code-Design)\n","6. [Architecture](#Architecture)\n","7. [Initialization](#Initialization)\n","8. [Stopping criteria:](#Stopping-criteria)\n","9. [Network Hyper-Parameters Tuning:](#Network-Hyper-Parameters-Tuning)\n","10. [Full Experimental Setup](#Full-Experimental-Setup)\n","11. [Experimental Results](#Experimental-Results)\n","\n","## Authors\n","* **Tomer Shahar** - [Tomer Shahar](https://github.com/Tomer-Shahar)\n","* **Nevo Itzhak** - [Nevo Itzhak](https://github.com/nevoit)\n","\n","## Purposes of The Assignment \n","Enabling students to experiment with building a convolutional neural net and using it on a real-world dataset  and problem.\n","In addition to practical knowledge in the “how to” of building the network, an additional goal is the integration of useful logging tools for gaining better insight into the training process. Finally, the students are expected to read, understand and (loosely) implement a scientific paper.\n","\n","In this assignment, you will use convolutional neural networks (CNNs) to carry out the task of facial recognition. As shown in class, CNNs are the current state-of-the-art approach for analyzing image-based datasets. More specifically, you will implement a one-shot classification solution. Wikipedia defines one-shot learning as follows: \n","“… an object categorization problem, found mostly in computer vision. Whereas most machine learning based object categorization algorithms require training on hundreds or thousands of samples/images and very large datasets, one-shot learning aims to learn information about object categories from one, or only a few, training samples/images.”\n","\n","Your work will be based on the paper [Siamese Neural Networks for One-shot Image Recognition](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf).\n","Your goal, like that of the paper, is to successfully execute a one-shot learning task for previously unseen objects. Given two facial images of previously unseen persons, your architecture will have to successfully determine whether they are the same person. While we encourage you to use the architecture described in this paper as a starting point, you are more than welcome to explore other possibilities.\n","\n","## Instructions\n","-\tUse the following dataset - [Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/index.html)\n","\n","(a) Download the dataset. Note: there are several versions of this dataset, use the version [found here](https://talhassner.github.io/home/projects/lfwa/index.html) (it’s called LFW-a, and is also used in the DeepFace paper).\n","\n","(b)\tUse the following train and test sets to train your model: [Train](http://vis-www.cs.umass.edu/lfw/pairsDevTrain.txt) \\ [Test](http://vis-www.cs.umass.edu/lfw/pairsDevTest.txt). [Remember - you will use your test set to perform one-shot learning. This division is set up so that no subject from test set is included in the train set]. Please note it is often a recommended to use a validation set when training your model. Make your own decision whether to use one and what percentage of (training) samples to allocate.\n","\n","(c) In your report, include an analysis of the dataset (size, number of examples – in total and per class – for the train and test sets, etc). Also provide the full experimental setup you used – batch sizes, the various parameters of your architecture, stopping criteria and any other relevant information. A good rule of thumb: if asked to recreate your work, a person should be able to do so based on the information you provide in your report.\n","\n","- Implement a Siamese network architecture while using the above-mentioned paper as a reference.\n","\n","(a) Provide a complete description of your architecture: number of layers, dimensions, filters etc. Make sure to mention parameters such as learning rates, optimization and regularization methods, and the use (if exists) of batchnorm.\n","\n","(b) Explain the reasoning behind the choices made in answer to the previous section. If your choices were the result of trial and error, please state the fact and describe the changes made throughout your experiments. Choosing certain parameter combination because they appeared in a previously published paper is a perfectly valid reason. \n","\n","- In addition to the details requested above, your report needs to include an analysis of your architecture’s performance. Please include the following information:\n","\n","(a) Convergence times, final loss and accuracy on the test set and holdout set\n","\n","(b) Graphs describing the loss on the training set throughout the training process\n","\n","(c) Performance when experimenting with the various parameters\n","\n","(d) Please include examples of accurate and misclassifications and try to determine why your model was not successful.\n","\n","(e) Any other information you consider relevant or found useful while training the model\n","\n","Please note the that report needs to reflect your decision-making process throughout the assignment. Please include all relevant information.\n","\n","- Please note that your work will not be evaluated solely on performance, but also on additional elements such as code correctness and documentation, a complete and clear documentation of your experimental process, analysis of your results and breadth and originality (where applicable).\n","\n","![Figure 1 - Siamese network for facial recognition](https://github.com/nevoit/Siamese-Neural-Networks-for-One-shot-Image-Recognition/blob/master/figures/figure%201%20explanation.png?raw=true \"Figure 1 - Siamese network for facial recognition\")\n","Figure 1 - Siamese network for facial recognition\n","\n","## Dataset Analysis\n","- Size: 5,749  people\n","- Number of examples –\n","    - Total:13,233 images. Some people have a single image and some have dozens.\n","    - Class 1 (identical): 1,100 pairs (in the training file) and 500 pairs (in the testing file)\n","    - Class 0 (non-identical): 1,100 pairs (in the training file) and 500 pairs (in the testing file)\n","    - Validation set: 20 percent of the training set - 440 pairs. (leaving 1760 pairs for the actual training data)\n","\n","## Code Design\n","Our code consists of three scripts:\n","1. Data_loader.py - contains the DataLoader class that loads image data, manipulates it, and writes it into a specified path in a certain format.\n","2. Siamese_network.py - contains the SiameseNetwork class that is our implementation of the network described in the paper. It includes many functions including one that builds the CNN used in the network and a function for finding the optimal hyperparameters.\n","3. Experiments.py - The script that is actually running. It calls the train and predict methods from SiameseNetwork.\n","\n","## Architecture\n","We mostly followed the architecture specified in the paper - The network is two Convolutional Neural Networks that are joined towards the end creating a Siamese network. However, our network is slightly smaller.\n","Number of layers: Each CNN, before being conjoined, has 5 layers (4 conventional and 1 fully connected layer). Then there is a distance layer, combining both CNNs, with a single output.\n","Dimensions: For the CNN part:\n","\n","| Layer | Input Size | Filters | Kernel | Maxpooling | Activation Function|\n","|---| --- | --- | --- |  ---  | --- |\n","|  1 | 105x105. Reshaped from 250x250 to adhere to the paper. | 64 | 10x10 | Yes, Stride of 2 |ReLU\n","| 2 | 64 filters of 10x10 | 128 | 7x7 | Yes, Stride of 2 | ReLU |\n","| 3 | 128 filters of 7x7 | 128 | 4x4 | Yes, Stride of 2 | ReLU |\n","| 4 | 128 filters of 4x4 | 256 | 4x4 | No | ReLU |\n","| 5 | 4096x1 Fully connected feature layer with drop out rate of 0.4 (Fraction of the input units to drop) | - | - |No | Sigmoid|\n","- There are two identical CNNs as described in the table.\n","- All CNN layers, except the last one (the fully connected layer), are defined with a fixed stride of 1 (as in the paper), padding value of ‘valid’ (with no zero paddings, the kernel is restricted to traverse only within the image), L2 as kernel regularizer with regularization factor of 2e-4 and perform batch normalization.\n","- For the last one (the fully connected layer), we used L2 as a kernel regularizer with a regularization factor of 2e-3.\n","- Please note Any and all parameters that were not mentioned used the default Tensorflow 2.0.0 Keras values.\n","- After the last layer, we add a layer that connects both sides thus creating the Siamese network. The activation function of this layer is a Sigmoid function which is handy since we have 2 classes (Same vs Not the same person).\n","- Total params: 38,954,049\n","- Trainable params: 38,952,897\n","- Non-trainable params: 1,152\n","\n","## Initialization\n","- Weight initialization for all edges was done as described in the paper: A normal distribution with a mean of 0 and a standard deviation of 0.01.\n","- Bias initialization was also done as it was in the paper, with a mean of 0.5 and a standard deviation of 0.01. However, the first layer has no bias. The paper doesn’t mention if they did this or not, but we found in this paper that occasionally, having no bias for the initial layer might be beneficial. This occurs when the layer is sufficiently large and the data is distributed fairly uniformly, which probably occurs in our case because the training set is predefined. Indeed, in our experiments adding a bias usually reduced the accuracy. Our final model doesn’t have a bias for the first layer.\n","- Note: the authors used a slightly different bias initialization for the fully connected layers.  Since there are so many edges, they sampled from a larger distribution. In our experiments, the same bias sampling as the rest of the network worked well so we used the same distribution.\n","- These are fairly typical methods of initializing weights and seemed to work well for the authors so we saw no reason to not imitate them (excluding the fully connected layer).\n","\n","## Stopping Criteria\n","We used the EarlyStopping function monitoring on the validation loss with a minimum delta of 0.1 (Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.) and patience 5 (Number of epochs with no improvement after which training will be stopped.). The direction is automatically inferred from the name of the monitored quantity (‘auto’).\n","\n","## Network Hyper-Parameters Tuning\n","NOTE: Here we explain the reasons behind the choices of the parameters.\n","After implementing our Siamese Network, we had to optimize the different parameters used. Many of them, such as layer size, were chosen based on the work in the paper and we decided against trying to find a better combination since the search space would be massive and we don’t know enough to narrow it down.\n","- Learning Rate: We tried many  different values, ranging from 0.1 to 0.00001. After running numerous experiments, we found 0.00005 to work the best.\n","- Optimizer: The paper didn’t specify so we used the robust and popular ADAM optimizer.\n","- Epochs: We tried epochs of 5, 10, 20 and 50. We found 10 to work the best.\n","- Batch size: We tried multiplications of 16 such as 16, 32 and 64. Our final model has a batch size of 32.\n","\n","## Full Experimental Setup\n","Validation Set: Empirically, we learned that using a validation set is better than not if there isn’t enough data. We used the fairly standard 80/20 ratio between training and validation which worked well.\n","- Batch sizes - 32\n","- Epochs - 10\n","- Stopping criteria - 5 epochs without improvement.\n","- Learning rate: 0.0005\n","- Min delta for improvement: 0.1\n","\n","##  Experimental Results\n","After implementing our Siamese Network, we ran it with many different settings as described above and chose the optimal settings. These are the results:\n","a.\tConvergence times, final loss and accuracy on the test set and holdout set:\n","- Final Loss on Testing set - 3.106\n","- Accuracy on Holdout set - 0.734 (73.4%)\n","- Final Loss on Testing set - 3.111\n","- Accuracy on Testing set - 0.731 (73.2%)\n","- Convergence time - 30 seconds\n","- Prediction time - less than 1 second\n","\n","b. Graphs describing the loss on the training set throughout the training process:\n","\n","![loss-epoch](https://github.com/nevoit/Siamese-Neural-Networks-for-One-shot-Image-Recognition/blob/master/figures/loss-epoch.PNG?raw=true \"loss-epoch\")\n","\n","Fig.2: Reduction in the loss function for each epoch. The validation set predicted the loss on the test set well.\n","\n","![loss-acc](https://github.com/nevoit/Siamese-Neural-Networks-for-One-shot-Image-Recognition/blob/master/figures/acc-epoch.PNG?raw=true \"loss-acc\")\n","\n","Fig.3: Accuracy of the training and validation sets for each epoch. For the validation set the accuracy plateaued after 2 epochs, but as you can see in fig.1 the loss continued to reduce explaining the increase in  accuracy for the test set for 2 more epochs.\n","\n","c. Performance when experimenting with various parameters:\n","We used the best parameters and changed some of them to test their effect, seed 0, learning rate 0.00005, batch_size 32, epochs 10 patience of 5, and minimum delta of 0.1.\n","\n","We tested the following learning rates: 0.000005, 0.00001, 0.00003 0.00005, 0.00007, 0.0001 and 0.001.\n","\n","![lr-acc](https://github.com/nevoit/Siamese-Neural-Networks-for-One-shot-Image-Recognition/blob/master/figures/acc_lr.PNG?raw=true \"lr-acc\")\n","\n","Fig.4: Here we can see that the learning rate around 0.0005 had similar results, but if it was too large or too small the results dropped drastically.\n","\n","We tested the following epochs: 1, 2, 3, 5, 10, 15, 20, 30 epochs.\n","\n","![ep-acc](https://github.com/nevoit/Siamese-Neural-Networks-for-One-shot-Image-Recognition/blob/master/figures/acc_epoch.PNG?raw=true \"ep-acc\")\n","\n","Fig.5:# of epochs didn’t change the accuracy much past 2 epochs.\n","\n","We tested the following batch sizes: 8, 16, 32, 48, 64.\n","\n","![bs-acc](https://github.com/nevoit/Siamese-Neural-Networks-for-One-shot-Image-Recognition/blob/master/figures/acc_bs.PNG?raw=true \"bs-acc\")\n","\n","Fig.6: Curiously, batch size distributes normally around 32 for the test set and is wildly different for the validation set.\n","\n","d. Please include examples of accurate classifications and misclassifications and try to determine why your model was not successful.\n","\n","Best correct classification:\n","Same person (prob: 0.9855): Unsurprising, as the images really are very similar.\n","\n","![same](https://github.com/nevoit/Siamese-Neural-Networks-for-One-shot-Image-Recognition/blob/master/figures/gordon_campbell.PNG?raw=true \"same\")\n","\n","Different people (prob: 0.0000379): It is quite clear that it’s two different people. Nothing too interesting here - The colors and facial expressions are very different.\n","\n","![babe](https://github.com/nevoit/Siamese-Neural-Networks-for-One-shot-Image-Recognition/blob/master/figures/babe_ruth_joshua_perper.PNG?raw=true \"babe\")\n","\n","Worst Misclassification:\n","Same person (prob:0.0587): Even though both are the same person, the images are radically different - In the left image, Candice is wearing sunglasses, has bright hair and is looking the other way. On the right, she has dark hair, no sunglasses and has her teeth showing. We theorize that most people would classify this wrong as well.\n","\n","![Candice_Bergen](https://github.com/nevoit/Siamese-Neural-Networks-for-One-shot-Image-Recognition/blob/master/figures/candice_bergen.PNG?raw=true \"Candice_Bergen\")\n","\n","Different people (prob: 0.9464): This is quite surprising since it’s quite apparent that this is not the same person, but the network had such high confidence that they are. Perhaps the coat resembles the hair lapping around her head.\n","\n","![lisa](https://github.com/nevoit/Siamese-Neural-Networks-for-One-shot-Image-Recognition/blob/master/figures/lisa_murkowski_svetlana_belousova.PNG?raw=true \"lisa\")\n","\n","e. Any other information you consider relevant or found useful while training the model\n","- We used K.clear_session() in order to make sure we are in a new session in each combination in the experiment (We imported consider K as tensorflow.keras.backend).\n","- We initialized the seeds using these lines:\n","\n","`os.environ['PYTHONHASHSEED'] = str(self.seed)`\n","\n","`random.seed(self.seed)`\n","\n","`np.random.seed(self.seed)`\n","\n","`tf.random.set_seed(self.seed)`\n"]},{"cell_type":"markdown","metadata":{},"source":["### Pip install"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-27T14:52:47.725197Z","iopub.status.busy":"2023-03-27T14:52:47.724724Z","iopub.status.idle":"2023-03-27T14:56:52.577062Z","shell.execute_reply":"2023-03-27T14:56:52.575769Z","shell.execute_reply.started":"2023-03-27T14:52:47.725095Z"},"id":"oBPiL4Aoqjwk","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /home/cytech/.local/lib/python3.8/site-packages (2.10.1)\n","Requirement already satisfied: keras<2.11,>=2.10.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (4.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: packaging in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (21.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (22.10.26)\n","Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (2.10.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (1.3.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (1.44.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (2.1.0)\n","Requirement already satisfied: libclang>=13.0.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (14.0.6)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (0.27.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: numpy>=1.20 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (1.23.4)\n","Requirement already satisfied: h5py>=2.9.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n","Requirement already satisfied: six>=1.12.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (3.19.6)\n","Requirement already satisfied: wrapt>=1.11.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n","Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/cytech/.local/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.9)\n","Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.34.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/cytech/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /home/cytech/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /home/cytech/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.30.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /home/cytech/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/cytech/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/cytech/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/cytech/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.12)\n","Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/cytech/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/cytech/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n","Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/cytech/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (6.1.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/cytech/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/cytech/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/cytech/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (1.0.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/cytech/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n","Requirement already satisfied: pillow in /home/cytech/.local/lib/python3.8/site-packages (9.2.0)\n","Requirement already satisfied: tqdm in /home/cytech/.local/lib/python3.8/site-packages (4.64.1)\n","Requirement already satisfied: keras in /home/cytech/.local/lib/python3.8/site-packages (2.10.0)\n"]}],"source":["!pip install tensorflow\n","!pip install pillow\n","!pip install tqdm\n","!pip install keras"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-03-27T14:58:01.283509Z","iopub.status.idle":"2023-03-27T14:58:01.284362Z","shell.execute_reply":"2023-03-27T14:58:01.283985Z","shell.execute_reply.started":"2023-03-27T14:58:01.283950Z"},"id":"O10BFXSipobN","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded data loader\n"]}],"source":["import os\n","import pickle\n","\n","import tqdm\n","from PIL import Image, ImageOps\n","import numpy as np\n","\n","\n","class DataLoader(object):\n","    \"\"\"\n","    Class for loading data from image files\n","    \"\"\"\n","    def __init__(self, width, height, cells, data_path, output_path):\n","        \"\"\"\n","        Proper width and height for each image.\n","        \"\"\"\n","        self.width = width\n","        self.height = height\n","        self.cells = cells\n","        self.data_path = data_path\n","        self.output_path = output_path\n","\n","    def _open_image(self, path):\n","        \"\"\"\n","        Using the Image library we open the image in the given path. The path must lead to a .jpg file.\n","        We then resize it to 105x105 like in the paper (the dataset contains 250x250 images.)\n","\n","        Returns the image as a numpy array.\n","        \"\"\"\n","        image = Image.open(path)\n","        image = ImageOps.grayscale(image)\n","        image = image.resize((self.width, self.height))\n","        data = np.asarray(image)\n","        data = np.array(data, dtype='float64')\n","        return data\n","\n","    def convert_image_to_array(self, stone, image_num, data_path, predict=False):\n","        \"\"\"\n","        Given a person, image number and datapath, returns a numpy array which represents the image.\n","        predict - whether this function is called during training or testing. If called when training, we must reshape\n","        the images since the given dataset is not in the correct dimensions.\n","        \"\"\"\n","        max_zeros = 4\n","        # image_num = '0' * max_zeros + image_num\n","        # image_num = image_num[-max_zeros:]\n","        image_path = os.path.join(data_path, 'stone_samples', stone, f'{image_num}.png')\n","        image_data = self._open_image(image_path)\n","        if not predict:\n","            image_data = image_data.reshape(self.width, self.height, self.cells)\n","        return image_data\n","\n","    def load(self, set_name):\n","        \"\"\"\n","        Writes into the given output_path the images from the data_path.\n","        dataset_type = train or test\n","        \"\"\"\n","        file_path = os.path.join(self.data_path, f'{set_name}.txt')\n","        print(file_path)\n","        print('Loading dataset...')\n","        x_first = []\n","        x_second = []\n","        y = []\n","        names = []\n","        with open(file_path, 'r') as file:\n","            lines = file.readlines()\n","        for line in tqdm.tqdm(lines):\n","            line = line.split()\n","            if len(line) == 4:  # Class 0 - non-identical\n","                names.append(line)\n","                first_stone_name, first_image_num, second_stone_name, second_image_num = line[0], line[1], line[2], \\\n","                                                                                           line[3]\n","                first_image = self.convert_image_to_array(stone=first_stone_name, image_num=first_image_num, data_path=self.data_path)\n","                second_image = self.convert_image_to_array(stone=second_stone_name,\n","                                                           image_num=second_image_num,\n","                                                           data_path=self.data_path)\n","                x_first.append(first_image)\n","                x_second.append(second_image)\n","                y.append(0)\n","            elif len(line) == 3:  # Class 1 - identical\n","                names.append(line)\n","                stone_name, first_image_num, second_image_num = line[0], line[1], line[2]\n","                first_image = self.convert_image_to_array(stone=stone_name,\n","                                                          image_num=first_image_num,\n","                                                          data_path=self.data_path)\n","                second_image = self.convert_image_to_array(stone=stone_name,\n","                                                           image_num=second_image_num,\n","                                                           data_path=self.data_path)\n","                x_first.append(first_image)\n","                x_second.append(second_image)\n","                y.append(1)\n","            elif len(line) == 1:\n","                print(f'line with a single value: {line}')\n","        print('Done loading dataset')\n","        with open(self.output_path, 'wb') as f:\n","            pickle.dump([[x_first, x_second], y, names], f)\n","\n","\n","print(\"Loaded data loader\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-27T14:56:52.608079Z","iopub.status.busy":"2023-03-27T14:56:52.607622Z","iopub.status.idle":"2023-03-27T14:57:03.144545Z","shell.execute_reply":"2023-03-27T14:57:03.143293Z","shell.execute_reply.started":"2023-03-27T14:56:52.608039Z"},"id":"u5dO2Y-Bpo_x","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded Siamese Network\n"]}],"source":["import os\n","import pickle\n","import random\n","\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import Input, Sequential, Model\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Lambda, BatchNormalization, Activation, \\\n","    Dropout\n","from tensorflow.keras.regularizers import l2\n","\n","\n","class SiameseNetwork(object):\n","    def __init__(self, seed, width, height, cells, loss, metrics, optimizer, dropout_rate):\n","        \"\"\"\n","        Seed - The seed used to initialize the weights\n","        width, height, cells - used for defining the tensors used for the input images\n","        loss, metrics, optimizer, dropout_rate - settings used for compiling the siamese model (e.g., 'Accuracy' and 'ADAM)\n","        \"\"\"\n","        K.clear_session()\n","        self.load_file = None\n","        self.seed = seed\n","        self.initialize_seed()\n","        self.optimizer = optimizer\n","\n","        # Define the matrices for the input images\n","        input_shape = (width, height, cells)\n","        left_input = Input(input_shape)\n","        right_input = Input(input_shape)\n","\n","        # Get the CNN architecture as presented in the paper (read the readme for more information)\n","        model = self._get_architecture(input_shape)\n","        encoded_l = model(left_input)\n","        encoded_r = model(right_input)\n","\n","        # Add a layer to combine the two CNNs\n","        L1_layer = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))\n","        L1_siamese_dist = L1_layer([encoded_l, encoded_r])\n","        L1_siamese_dist = Dropout(dropout_rate)(L1_siamese_dist)\n","\n","        # An output layer with Sigmoid activation function\n","        prediction = Dense(1, activation='sigmoid', bias_initializer=self.initialize_bias)(L1_siamese_dist)\n","\n","        siamese_net = Model(inputs=[left_input, right_input], outputs=prediction)\n","        self.siamese_net = siamese_net\n","        self.siamese_net.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n","\n","    def initialize_seed(self):\n","        \"\"\"\n","        Initialize seed all for environment\n","        \"\"\"\n","        os.environ['PYTHONHASHSEED'] = str(self.seed)\n","        random.seed(self.seed)\n","        np.random.seed(self.seed)\n","        tf.random.set_seed(self.seed)\n","\n","    def initialize_weights(self, shape, dtype=None):\n","        \"\"\"\n","        Called when initializing the weights of the siamese model, uses the random_normal function of keras to return a\n","        tensor with a normal distribution of weights.\n","        \"\"\"\n","        return K.random_normal(shape, mean=0.0, stddev=0.01, dtype=dtype, seed=self.seed)\n","\n","    def initialize_bias(self, shape, dtype=None):\n","        \"\"\"\n","        Called when initializing the biases of the siamese model, uses the random_normal function of keras to return a\n","        tensor with a normal distribution of weights.\n","        \"\"\"\n","        return K.random_normal(shape, mean=0.5, stddev=0.01, dtype=dtype, seed=self.seed)\n","\n","    def _get_architecture(self, input_shape):\n","        \"\"\"\n","        Returns a Convolutional Neural Network based on the input shape given of the images. This is the CNN network\n","        that is used inside the siamese model. Uses parameters from the siamese one shot paper.\n","        \"\"\"\n","        model = Sequential()\n","        model.add(\n","            Conv2D(filters=64,\n","                   kernel_size=(10, 10),\n","                   input_shape=input_shape,\n","                   kernel_initializer=self.initialize_weights,\n","                   kernel_regularizer=l2(2e-4),\n","                   name='Conv1'\n","                   ))\n","        model.add(BatchNormalization())\n","        model.add(Activation(\"relu\"))\n","        model.add(MaxPooling2D())\n","\n","        model.add(\n","            Conv2D(filters=128,\n","                   kernel_size=(7, 7),\n","                   kernel_initializer=self.initialize_weights,\n","                   bias_initializer=self.initialize_bias,\n","                   kernel_regularizer=l2(2e-4),\n","                   name='Conv2'\n","                   ))\n","        model.add(BatchNormalization())\n","        model.add(Activation(\"relu\"))\n","        model.add(MaxPooling2D())\n","\n","        model.add(\n","            Conv2D(filters=128,\n","                   kernel_size=(4, 4),\n","                   kernel_initializer=self.initialize_weights,\n","                   bias_initializer=self.initialize_bias,\n","                   kernel_regularizer=l2(2e-4),\n","                   name='Conv3'\n","                   ))\n","        model.add(BatchNormalization())\n","        model.add(Activation(\"relu\"))\n","        model.add(MaxPooling2D())\n","\n","        model.add(\n","            Conv2D(filters=256,\n","                   kernel_size=(4, 4),\n","                   kernel_initializer=self.initialize_weights,\n","                   bias_initializer=self.initialize_bias,\n","                   kernel_regularizer=l2(2e-4),\n","                   name='Conv4'\n","                   ))\n","        model.add(BatchNormalization())\n","        model.add(Activation(\"relu\"))\n","\n","        model.add(Flatten())\n","        model.add(\n","            Dense(4096,\n","                  activation='sigmoid',\n","                  kernel_initializer=self.initialize_weights,\n","                  kernel_regularizer=l2(2e-3),\n","                  bias_initializer=self.initialize_bias))\n","        return model\n","\n","    def _load_weights(self, weights_file):\n","        \"\"\"\n","        A function that attempts to load pre-existing weight files for the siamese model. If it succeeds then returns\n","        True and updates the weights, otherwise False.\n","        :return True if the file is already exists\n","        \"\"\"\n","        # self.siamese_net.summary()\n","        self.load_file = weights_file\n","        if os.path.exists(weights_file):  # if the file is already exists, load and return true\n","            print('Loading pre-existed weights file')\n","            self.siamese_net.load_weights(weights_file)\n","            return True\n","        return False\n","\n","    def fit(self, weights_file, train_path, validation_size, batch_size, epochs, early_stopping, patience, min_delta):\n","        \"\"\"\n","        Function for fitting the model. If the weights already exist, just return the summary of the model. Otherwise,\n","        perform a whole train/validation/test split and train the model with the given parameters.\n","        \"\"\"\n","        with open(train_path, 'rb') as f:\n","            x_train, y_train, names = pickle.load(f)\n","        \"\"\"\n","        X_train[0]:  |----------x_train_0---------------------------|-------x_val_0--------|\n","        X_train[1]:  |----------x_train_1---------------------------|-------x_val_1--------|\n","        y_train:     |----------y_train_0 = y_train_1---------------|----y_val_0=y_val_1---|\n","        \"\"\"\n","        x_train_0, x_val_0, y_train_0, y_val_0 = train_test_split(x_train[0], y_train,\n","                                                                  test_size=validation_size,\n","                                                                  random_state=self.seed)\n","        x_train_1, x_val_1, y_train_1, y_val_1 = train_test_split(x_train[1], y_train,\n","                                                                  test_size=validation_size,\n","                                                                  random_state=self.seed)\n","        x_train_0 = np.array(x_train_0, dtype='float64')\n","        x_val_0 = np.array(x_val_0, dtype='float64')\n","        x_train_1 = np.array(x_train_1, dtype='float64')\n","        x_val_1 = np.array(x_val_1, dtype='float64')\n","        x_train = [x_train_0, x_train_1]\n","        x_val = [x_val_0, x_val_1]\n","        if y_train_0 != y_train_1 and y_val_0 != y_val_1:\n","            raise Exception(\"y train lists or y validation list do not equal\")\n","        y_train_both = np.array(y_train_0, dtype='float64')\n","        y_val_both = np.array(y_val_0, dtype='float64')\n","        if not self._load_weights(weights_file=weights_file):\n","            print('No such pre-existed weights file')\n","            print('Beginning to fit the model')\n","            callback = []\n","            if early_stopping:\n","                \"\"\"\n","                We used the EarlyStopping function monitoring on the validation loss with a minimum delta of 0.1\n","                (Minimum change in the monitored quantity to qualify as an improvement, i.e.\n","                an absolute change of less than min_delta, will count as no improvement.) and patience 5 \n","                (Number of epochs with no improvement after which training will be stopped.).\n","                The direction is automatically inferred from the name of the monitored quantity (‘auto’).\n","                \"\"\"\n","                es = EarlyStopping(monitor='val_loss', min_delta=min_delta, patience=patience, mode='auto', verbose=1)\n","                callback.append(es)\n","            self.siamese_net.fit(x_train, y_train_both, batch_size=batch_size, epochs=epochs,\n","                                 validation_data=(x_val, y_val_both), callbacks=callback, verbose=1)\n","            self.siamese_net.save_weights(self.load_file)\n","        # evaluate on the testing set\n","        loss, accuracy = self.siamese_net.evaluate(x_val, y_val_both, batch_size=batch_size)\n","        print(f'Loss on Validation set: {loss}')\n","        print(f'Accuracy on Validation set: {accuracy}')\n","\n","    def evaluate(self, test_file, batch_size, analyze=False):\n","        \"\"\"\n","        Function for evaluating the final model after training.\n","        test_file - file path to the test file.\n","        batch_size - the batch size used in training.\n","\n","        Returns the loss and accuracy results.\n","        \"\"\"\n","        with open(test_file, 'rb') as f:\n","            x_test, y_test, names = pickle.load(f)\n","        print(f'Available Metrics: {self.siamese_net.metrics_names}')\n","        y_test = np.array(y_test, dtype='float64')\n","        x_test[0] = np.array(x_test[0], dtype='float64')\n","        x_test[1] = np.array(x_test[1], dtype='float64')\n","        # evaluate on the test set\n","        loss, accuracy = self.siamese_net.evaluate(x_test, y_test, batch_size=batch_size)\n","        if analyze:\n","            self._analyze(x_test, y_test, names)\n","        return loss, accuracy\n","\n","    def _analyze(self, x_test, y_test, names):\n","        \"\"\"\n","        Function used for evaluating our network in the methods proposed in the assignment.\n","        We will find:\n","        - The person who has 2 images that are the most dissimilar to each other\n","        - The person with the two images that are the most similar to each other\n","        - Two people with the most dissimilar images, and\n","        - The two people with the most similar images.\n","        \"\"\"\n","        best_class_0_prob = 1  # correct classification for different people, y=0, prediction->0\n","        best_class_0_name = None\n","        worst_class_0_prob = 0  # misclassification for different people, y=0, prediction->1\n","        worst_class_0_name = None\n","        best_class_1_prob = 0  # correct classification for same people, y=1, prediction->1\n","        best_class_1_name = None\n","        worst_class_1_prob = 1  # misclassification for same people, y=1, prediction->0\n","        worst_class_1_name = None\n","        prob = self.siamese_net.predict(x_test)\n","        for pair_index in range(len(names)):\n","            name = names[pair_index]\n","            y_pair = y_test[pair_index]\n","            pair_prob = prob[pair_index][0]\n","            if y_pair == 0:  # different people (actual)\n","                if pair_prob < best_class_0_prob:  # correct classification for different people, y=0, prediction->0\n","                    best_class_0_prob = pair_prob\n","                    best_class_0_name = name\n","                if pair_prob > worst_class_0_prob:  # misclassification for different people, y=0, prediction->1\n","                    worst_class_0_prob = pair_prob\n","                    worst_class_0_name = name\n","            else:  # the same person (actual)\n","                if pair_prob > best_class_1_prob:  # correct classification for same people, y=1, prediction->1\n","                    best_class_1_prob = pair_prob\n","                    best_class_1_name = name\n","                if pair_prob < worst_class_1_prob:  # misclassification for same people, y=1, prediction->0\n","                    worst_class_1_prob = pair_prob\n","                    worst_class_1_name = name\n","\n","        print(f'correct classification for different people, y=0, prediction->0, name: {best_class_0_name} | prob: {best_class_0_prob}')\n","        print(f'misclassification for different people, y=0, prediction->1, name: {worst_class_0_name} | prob: {worst_class_0_prob}')\n","        print(f'correct classification for same people, y=1, prediction->1, name: {best_class_1_name} | prob: {best_class_1_prob}')\n","        print(f'misclassification for same people, y=1, prediction->0, name: {worst_class_1_name} | prob: {worst_class_1_prob}')\n","\n","\n","    def predict_stone_class(self, image):\n","        \"\"\"\n","        Function for predicting the stone class of an image.\n","        image - the image to predict the stone class of.\n","\n","        Returns the predicted stone class.\n","        \"\"\"\n","        # Prepraing the litho image for the network\n","        image = np.array(image, dtype='float64')\n","        image = image.reshape(1, image.shape[0], image.shape[1], image.shape[2])\n","        # Make de set of comparison with the legend images\n","        for pattern in legend_patterns:\n","            prediction = self.siamese_net.predict(image)...\n","        # Keep the legend images with the highest probability\n","        return prediction\n","    \n","\n","print(\"Loaded Siamese Network\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-27T14:57:03.147534Z","iopub.status.busy":"2023-03-27T14:57:03.146875Z","iopub.status.idle":"2023-03-27T14:58:01.282021Z","shell.execute_reply":"2023-03-27T14:58:01.280392Z","shell.execute_reply.started":"2023-03-27T14:57:03.147492Z"},"id":"ohgCVhwgsQSU","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["IS_KAGGLE:  False\n","posix\n","Starting the experiments\n","./data/test.txt\n","Loading dataset...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14/14 [00:00<00:00, 563.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["['15_3-4_SANDSTONE', '1', '2']\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","['15_3-4_CLAY', '1', '2']\n","(124, 124)\n","(124, 124)\n","['15_3-4_COAL_LIGNITE', '1', '5']\n","(124, 124)\n","(124, 124)\n","['15_3-4_LIMESTONE', '0', '1']\n","(124, 124)\n","(124, 124)\n","['15_3-4_MARL', '1', '5']\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","['15_3-4_SAND', '1', '7']\n","(124, 124)\n","(124, 124)\n","['15_3-4_SAND_Coarse', '6', '7']\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","['15_3-4_TUFF', '1', '477']\n","(124, 124)\n","(124, 124)\n","Done loading dataset\n","./data/train.txt\n","Loading dataset...\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/14 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["['15_3-4_SANDSTONE', '1', '2']\n","(124, 124)\n","(124, 124)\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 14/14 [00:00<00:00, 584.86it/s]"]},{"name":"stdout","output_type":"stream","text":["(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","['15_3-4_CLAY', '1', '2']\n","(124, 124)\n","(124, 124)\n","['15_3-4_COAL_LIGNITE', '1', '5']\n","(124, 124)\n","(124, 124)\n","['15_3-4_LIMESTONE', '0', '1']\n","(124, 124)\n","(124, 124)\n","['15_3-4_MARL', '1', '5']\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","['15_3-4_SAND', '1', '7']\n","(124, 124)\n","(124, 124)\n","['15_3-4_SAND_Coarse', '6', '7']\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","(124, 124)\n","['15_3-4_TUFF', '1', '477']\n","(124, 124)\n","(124, 124)\n","Done loading dataset\n","Running combination with seed_0_lr_5e-05_bs_32_ep_10_val_0.2_es_True_pa_5_md_0.1\n"]},{"name":"stderr","output_type":"stream","text":["\n","/home/cytech/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["No such pre-existed weights file\n","Beginning to fit the model\n","Epoch 1/10\n","1/1 [==============================] - 4s 4s/step - loss: 14.2215 - accuracy: 0.1818 - val_loss: 14.1083 - val_accuracy: 0.6667\n","Epoch 2/10\n","1/1 [==============================] - 2s 2s/step - loss: 13.5798 - accuracy: 1.0000 - val_loss: 14.0835 - val_accuracy: 0.6667\n","Epoch 3/10\n","1/1 [==============================] - 2s 2s/step - loss: 13.4532 - accuracy: 1.0000 - val_loss: 14.0553 - val_accuracy: 0.6667\n","Epoch 4/10\n","1/1 [==============================] - 2s 2s/step - loss: 13.3977 - accuracy: 1.0000 - val_loss: 14.0215 - val_accuracy: 0.6667\n","Epoch 5/10\n","1/1 [==============================] - 2s 2s/step - loss: 13.3563 - accuracy: 1.0000 - val_loss: 13.9840 - val_accuracy: 0.6667\n","Epoch 6/10\n","1/1 [==============================] - 2s 2s/step - loss: 13.3172 - accuracy: 1.0000 - val_loss: 13.9442 - val_accuracy: 0.6667\n","Epoch 7/10\n","1/1 [==============================] - 2s 2s/step - loss: 13.2778 - accuracy: 1.0000 - val_loss: 13.9024 - val_accuracy: 0.6667\n","Epoch 8/10\n","1/1 [==============================] - 3s 3s/step - loss: 13.2363 - accuracy: 1.0000 - val_loss: 13.8590 - val_accuracy: 0.6667\n","Epoch 9/10\n","1/1 [==============================] - 2s 2s/step - loss: 13.1926 - accuracy: 1.0000 - val_loss: 13.8148 - val_accuracy: 0.6667\n","Epoch 10/10\n","1/1 [==============================] - 2s 2s/step - loss: 13.1487 - accuracy: 1.0000 - val_loss: 13.7695 - val_accuracy: 0.6667\n","1/1 [==============================] - 0s 175ms/step - loss: 13.7695 - accuracy: 0.6667\n","Loss on Validation set: 13.769503593444824\n","Accuracy on Validation set: 0.6666666865348816\n","Available Metrics: ['loss', 'accuracy']\n","1/1 [==============================] - 0s 450ms/step - loss: 13.7344 - accuracy: 0.5714\n","1/1 [==============================] - 1s 588ms/step\n","correct classification for different people, y=0, prediction->0, name: ['15_3-4_SILTSTONE', '478', '15_3-4_SAND', '7'] | prob: 0.5458135604858398\n","misclassification for different people, y=0, prediction->1, name: ['15_3-4_ROCK_SALT', '474', '15_3-4_LIMESTONE', '1'] | prob: 0.608163595199585\n","correct classification for same people, y=1, prediction->1, name: ['15_3-4_TUFF', '1', '477'] | prob: 0.6439122557640076\n","misclassification for same people, y=1, prediction->0, name: ['15_3-4_COAL_LIGNITE', '1', '5'] | prob: 0.5811665654182434\n","Loss on Testing set: 13.734379768371582\n","Accuracy on Testing set: 0.5714285969734192\n","Total Running Time: 28.366968631744385\n"]}],"source":["import os\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras.optimizers import Adam\n","\n","path_separator = os.path.sep\n","# Environment settings\n","IS_KAGGLE = False\n","print(\"IS_KAGGLE: \", IS_KAGGLE)\n","LOAD_DATA = True\n","IS_EXPERIMENT = False\n","train_name = 'test'\n","test_name = 'train'\n","WIDTH = HEIGHT = 124\n","CEELS = 1\n","loss_type = \"binary_crossentropy\"\n","validation_size = 0.2\n","early_stopping = True\n","\n","if IS_KAGGLE:\n","    # the google drive folder we used\n","    data_path = '..' + os.path.sep + os.path.join('input', 'faces2')\n","    output_path = './'\n","else:\n","    output_path = './data/'\n","    data_path = './data/'\n","    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","\n","\n","def run_combination(l, bs, ep, pat, md, seed, train_path, test_path):\n","    \"\"\"\n","    This function gets the parameters and run the experiment.\n","    :return: loss - loss on the testing set, accuracy - accuracy on the testing set\n","    \"\"\"\n","    # file types\n","    model_save_type = 'h5'\n","    # files paths\n","    initialize_seed(seed)\n","    parameters_name = f'seed_{seed}_lr_{l}_bs_{bs}_ep_{ep}_val_{validation_size}_' \\\n","                      f'es_{early_stopping}_pa_{pat}_md_{md}'\n","    print(f'Running combination with {parameters_name}')\n","    # A path for the weights\n","    load_weights_folder = os.path.join(output_path, 'weights')\n","    if not os.path.exists(load_weights_folder):\n","        os.mkdir(load_weights_folder)\n","    load_weights_path = os.path.join(load_weights_folder, f'weights_{parameters_name}.{model_save_type}')\n","\n","    siamese = SiameseNetwork(seed=seed, width=WIDTH, height=HEIGHT, cells=CEELS, loss=loss_type, metrics=['accuracy'],\n","                             optimizer=Adam(lr=l), dropout_rate=0.4)\n","    siamese.fit(weights_file=load_weights_path, train_path=train_path, validation_size=validation_size,\n","                batch_size=bs, epochs=ep, early_stopping=early_stopping, patience=pat,\n","                min_delta=md)\n","    loss, accuracy = siamese.evaluate(test_file=test_path, batch_size=bs, analyze=True)\n","    print(f'Loss on Testing set: {loss}')\n","    print(f'Accuracy on Testing set: {accuracy}')\n","    # predict_pairs(model)\n","    return loss, accuracy\n","\n","\n","def run():\n","    \"\"\"\n","    The main function that runs the training and experiments. Uses the global variables above.\n","    \"\"\"\n","    # file types\n","    data_set_save_type = 'pickle'\n","    train_path = os.path.join(output_path, f'{train_name}.{data_set_save_type}')  # A path for the train file\n","    test_path = os.path.join(output_path, f'{test_name}.{data_set_save_type}')  # A path for the test file\n","    if LOAD_DATA:  # If the training data already exists\n","        loader = DataLoader(width=WIDTH, height=HEIGHT, cells=CEELS, data_path=data_path, output_path=train_path)\n","        loader.load(set_name=train_name)\n","        loader = DataLoader(width=WIDTH, height=HEIGHT, cells=CEELS, data_path=data_path, output_path=test_path)\n","        loader.load(set_name=test_name)\n","\n","    result_path = os.path.join(output_path, f'results.csv')  # A path for the train file\n","    results = {'lr': [], 'batch_size': [], 'epochs': [], 'patience': [], 'min_delta': [], 'seed': [], 'loss': [],\n","               'accuracy': []}\n","    for l in lr:\n","        for bs in batch_size:\n","            for ep in epochs:\n","                for pat in patience:\n","                    for md in min_delta:\n","                        for seed in seeds:\n","                            loss, accuracy = run_combination(l=l, bs=bs, ep=ep, pat=pat, md=md, seed=seed,\n","                                                             train_path=train_path, test_path=test_path)\n","                            results['lr'].append(l)\n","                            results['batch_size'].append(bs)\n","                            results['epochs'].append(ep)\n","                            results['patience'].append(pat)\n","                            results['min_delta'].append(md)\n","                            results['seed'].append(seed)\n","                            results['loss'].append(loss)\n","                            results['accuracy'].append(accuracy)\n","    df_results = pd.DataFrame.from_dict(results)\n","    df_results.to_csv(result_path)\n","\n","\n","def initialize_seed(seed):\n","    \"\"\"\n","    Initialize all relevant environments with the seed.\n","    \"\"\"\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","\n","if __name__ == '__main__':\n","    if IS_EXPERIMENT:\n","        # Experiments settings\n","        seeds = [0]\n","        lr = [0.00005]\n","        batch_size = [32]\n","        epochs = [10]\n","        patience = [5]\n","        min_delta = [0.1]\n","    else:\n","        # Final settings\n","        seeds = [0]\n","        lr = [0.00005]\n","        batch_size = [32]\n","        epochs = [10]\n","        patience = [5]\n","        min_delta = [0.1]\n","\n","    print(os.name)\n","    start_time = time.time()\n","    print('Starting the experiments')\n","    run()\n","    print(f'Total Running Time: {time.time() - start_time}')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"2.7.18"}},"nbformat":4,"nbformat_minor":4}
