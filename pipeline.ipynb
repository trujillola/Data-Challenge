{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "dir = './NO_Quad_15/15_2-1/'\n",
    "\n",
    "image = cv2.imread(dir+'litho_sand_coal_silt.png')\n",
    "\n",
    "result = image.copy()\n",
    "\n",
    "# Convert to grayscale and apply Otsu's thresholding\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray,0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "cv2.imwrite(dir+\"thresh.png\", thresh)\n",
    "\n",
    "# Detect horizontal lines\n",
    "horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40,1))\n",
    "detect_horizontal = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=1)\n",
    "detect_horizontal = cv2.dilate(detect_horizontal,horizontal_kernel,iterations = 1)\n",
    "cnts = cv2.findContours(detect_horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "for c in cnts:\n",
    "    cv2.drawContours(result, [c], 0, (36,255,12), 1)\n",
    "\n",
    "cv2.imwrite(dir+\"split.png\", result)\n",
    "\n",
    "# # Find maximum of x and minimum\n",
    "x_start = 0\n",
    "x_end = 42\n",
    "y_top = cnts[0][0][0][1]\n",
    "y_end = image.shape[0]\n",
    "\n",
    "if y_end - y_top >= 5:\n",
    "    cv2.imwrite(dir+str(0)+\".png\", image[y_top:y_end, x_start:x_end])\n",
    "\n",
    "for i in range(len(cnts)-1):\n",
    "    y_end = cnts[i][0][0][1]\n",
    "    y_top= cnts[i+1][0][0][1]\n",
    "    \n",
    "    if y_end - y_top >= 5:\n",
    "        cv2.imwrite(dir+str(i+1)+\".png\", image[y_top:y_end, x_start:x_end])\n",
    "\n",
    "y_end = cnts[len(cnts)-1][0][0][1]\n",
    "y_top = 1\n",
    "\n",
    "if y_end - y_top >= 5:\n",
    "    cv2.imwrite(dir+str(len(cnts))+\".png\", image[y_top:y_end, x_start:x_end])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Classe prédite : sand\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Classe prédite : coal_lignite\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Classe prédite : coal_lignite\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "Classe prédite : coal_lignite\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "Classe prédite : coal_lignite\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "Classe prédite : marl\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "Classe prédite : coal_lignite\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "Classe prédite : sand\n"
     ]
    }
   ],
   "source": [
    "#prédire la classe de chaque image (mathis) avec model.h5 entrainé avec un ResNet50\n",
    "#prédiction de plusieurs images d'une même classe\n",
    "from codecarbon import EmissionsTracker\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#class_labels = ['anhydrite', 'calcareous_dolomite', 'chalk', 'chert', 'clay', 'coal_lignite', 'conglomerate', 'dolomite', 'dolomitic_limestone', 'fossiliferous', 'glauconite', 'gypsum', 'limestone', 'marl', 'metamorphic', 'pyrite', 'salt', 'sand', 'shale', 'silt', 'tuff']\n",
    "#class_labels = ['limestone', 'marl', 'marl_limestone', 'salt', 'sand', 'sand_clay', 'silt']\n",
    "class_labels = ['coal_lignite', 'marl', 'marl_limestone', 'sand', 'sand_clay']\n",
    "model = load_model('model_inception.h5')\n",
    "\n",
    "# Charger toutes les images du dossier test\n",
    "test_dir = './NO_Quad_15/15_2-1/'\n",
    "\n",
    "nb_fichiers = len([f for f in os.listdir(test_dir) if os.path.isfile(os.path.join(test_dir, f))])\n",
    "\n",
    "for i in range(0, nb_fichiers-4): \n",
    "    # Ouvrir l'image\n",
    "    image_files = glob.glob(os.path.join(test_dir, f\"{i}.png\"))\n",
    "\n",
    "    for image_file in image_files:\n",
    "        img = load_img(image_file, target_size=(224, 224))\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        preds = model.predict(x)\n",
    "\n",
    "        # Trouver la classe prédite et afficher le résultat\n",
    "        class_idx = np.argmax(preds[0])\n",
    "        predicted_prob = preds[0][class_idx]\n",
    "        predicted_label = class_labels[class_idx]\n",
    "            # Vérifier si la probabilité de la classe prédite est inférieure à 50%\n",
    "        # if predicted_prob < 0.5:\n",
    "        #     predicted_label = \"non identifié\"\n",
    "        # else:\n",
    "        #     predicted_label = class_labels[class_idx]\n",
    "        #predicted_label = class_labels[class_idx]\n",
    "        print(\"Classe prédite :\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 102ms/step\n",
      "La classe prédite qui a été choisie le plus grand nombre de fois est : coal_lignite\n",
      "Cette classe a été choisie 5 fois.\n"
     ]
    }
   ],
   "source": [
    "# Initialiser un dictionnaire qui va contenir le nombre de prédictions pour chaque classe\n",
    "class_predictions = {m: 0 for m in class_labels}\n",
    "\n",
    "# Parcourir toutes les images\n",
    "for i in range(0, nb_fichiers-4):  \n",
    "    # Ouvrir l'image\n",
    "    image_files = glob.glob(os.path.join(test_dir, f\"{i}.png\"))\n",
    "\n",
    "    for image_file in image_files:\n",
    "        img = load_img(image_file, target_size=(224, 224))\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        preds = model.predict(x)\n",
    "\n",
    "        # Trouver la classe prédite et incrémenter le compteur correspondant\n",
    "        class_idx = np.argmax(preds[0])\n",
    "        predicted_label = class_labels[class_idx]\n",
    "        class_predictions[predicted_label] += 1\n",
    "\n",
    "# Trouver la classe prédite qui a été choisie le plus grand nombre de fois\n",
    "most_predicted_class = max(class_predictions, key=class_predictions.get)\n",
    "# Trouver le nombre de fois que cette classe a été choisie\n",
    "most_predictions_count = class_predictions[most_predicted_class]\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"La classe prédite qui a été choisie le plus grand nombre de fois est : {most_predicted_class}\")\n",
    "print(f\"Cette classe a été choisie {most_predictions_count} fois.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 123ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n"
     ]
    }
   ],
   "source": [
    "#calcul de la hauteur relative de tous les png\n",
    "import openpyxl\n",
    "from PIL import Image\n",
    "from openpyxl.chart import PieChart, Reference\n",
    "\n",
    "# Ouvrir les images et stocker les hauteurs relatives pour chaque matériau\n",
    "heights = {m: [] for m in class_labels}\n",
    "\n",
    "for i in range(1, nb_fichiers-4): \n",
    "    # Ouvrir l'image\n",
    "    img = Image.open(f\"./NO_Quad_15/15_2-1/{i}.png\")\n",
    "\n",
    "    # Calculer la hauteur (en pixels)\n",
    "    # pas besoin de la largeur qui sera identique\n",
    "    height = img.height\n",
    "    valeur_relative = height / 100\n",
    "\n",
    "    # Ouvrir l'image\n",
    "    image_files = glob.glob(os.path.join(test_dir, f\"{i}.png\"))\n",
    "\n",
    "    for image_file in image_files:\n",
    "        img = load_img(image_file, target_size=(224, 224))\n",
    "        x = img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        preds = model.predict(x)\n",
    "\n",
    "        # Trouver la classe prédite et afficher le résultat\n",
    "        class_idx = np.argmax(preds[0])\n",
    "        predicted_label = class_labels[class_idx]\n",
    "\n",
    "        # Ajouter la hauteur relative à la liste correspondant au matériau aléatoire choisi\n",
    "        class_label = predicted_label\n",
    "        #print(class_label)\n",
    "        heights[class_label].append(valeur_relative)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#création du tableur excel et remplissage\n",
    "#attention aux indices de remplissage de l'excel qui doivent être adaptatifs\n",
    "# Créer le tableur Excel\n",
    "wb = openpyxl.Workbook()\n",
    "ws = wb.active\n",
    "\n",
    "# Ajouter les hauteurs relatives pour chaque matériau dans le tableur\n",
    "for i, m in enumerate(class_labels):\n",
    "    # Ajouter le nom du matériau dans la première colonne\n",
    "    ws.cell(row=i+2, column=1, value=m)\n",
    "\n",
    "    # Ajouter les hauteurs relatives dans les colonnes suivantes\n",
    "    for j, h in enumerate(heights[m]):\n",
    "        ws.cell(row=i+2, column=j+2, value=h)\n",
    "\n",
    "# Ajouter la ligne des totaux en bas\n",
    "#for j in range(2, 7):\n",
    "#10 etant le nb de fois qu'un matériau est prédit\n",
    "for j in range(2, most_predictions_count+2):\n",
    "    sub_sum = sum(ws.cell(row=i, column=j).value or 0 for i in range(2, len(class_labels)+2))\n",
    "    ws.cell(row=len(class_labels)+2, column=j, value=sub_sum)\n",
    "\n",
    "# Ajouter la colonne des totaux\n",
    "for i in range(2, len(class_labels)+3):\n",
    "    sub_sum = sum(ws.cell(row=i, column=j).value or 0 for j in range(2,  len(class_labels)))\n",
    "    ws.cell(row=i, column=most_predictions_count+2, value=sub_sum)\n",
    "\n",
    "# Ajouter la colonne des pourcentages\n",
    "for i in range(2, len(class_labels)+2):\n",
    "    total = ws.cell(row=len(class_labels)+2, column=most_predictions_count+2).value\n",
    "    percent = sum(ws.cell(row=i, column=j).value or 0 for j in range(2, most_predictions_count+2)) / ws.cell(row=len(class_labels)+2, column=most_predictions_count+2).value\n",
    "    ws.cell(row=i, column=most_predictions_count+3, value=percent).number_format = '0.00%'\n",
    "\n",
    "\n",
    "# Enregistrer le tableur Excel\n",
    "#wb.save(\"resultats_tmp.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#génération du graphique camembert\n",
    "# Créer le graphique camembert\n",
    "chart = PieChart()\n",
    "chart.title = \"Pourcentage Lithologie\"\n",
    "\n",
    "\n",
    "# Ajouter les données du graphique\n",
    "labels = Reference(ws, min_col=1, min_row=2, max_row=len(class_labels)+1)\n",
    "data = Reference(ws, min_col=most_predictions_count+3, min_row=1, max_row=len(class_labels)+1)\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "chart.set_categories(labels)\n",
    "\n",
    "# Ajouter le graphique au tableur\n",
    "ws.add_chart(chart, \"J2\")\n",
    "\n",
    "# Enregistrer le tableur Excel\n",
    "wb.save(\"resultats.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
